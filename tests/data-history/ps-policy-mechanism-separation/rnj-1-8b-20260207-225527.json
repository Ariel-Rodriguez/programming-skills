{
  "skill": "ps-policy-mechanism-separation",
  "severity": "WARN",
  "model": "rnj-1:8b",
  "skill_version": "1.0.0",
  "baseline_rate": 100,
  "skill_rate": 100,
  "baseline_rating": "regular",
  "skill_rating": "good",
  "baseline_pass_count": "2/2",
  "skill_pass_count": "2/2",
  "improvement": 0,
  "results": [
    {
      "name": "uploader_flexibility",
      "input": "Our `S3Uploader` class currently hardcodes a 30-second timeout and 3 retries. \n\nWe now need to use it for 1GB video files (which need 1 hour timeout) and for tiny 1KB JSON files (which need 500ms timeout).\n\nRedesign the class so that the *rules* (timeouts, retries) are separated from the *work* (uploading bytes).",
      "expected": {
        "focus": "Does the solution accept a config/policy object or strategy function?"
      },
      "baseline": {
        "pass": true,
        "response_preview": "To redesign the `S3Uploader` class so that the rules (timeouts, retries) are separated from the work...",
        "response_full": "To redesign the `S3Uploader` class so that the rules (timeouts, retries) are separated from the work (uploading bytes), we can introduce a configuration object or parameters that can be passed to the `S3Uploader` class. This way, the rules can be easily adjusted based on the type of file being uploaded.\n\nHere's how you can redesign the `S3Uploader` class:\n\n```python\nimport time\nimport random\n\nclass S3Uploader:\n    def __init__(self, timeout, retries):\n        self.timeout = timeout\n        self.retries = retries\n\n    def upload(self, data):\n        attempt = 0\n        while attempt < self.retries:\n            try:\n                # Simulate upload process\n                print(f\"Uploading data of size {len(data)} bytes...\")\n                time.sleep(self.timeout)  # Simulate upload time\n                print(\"Upload successful!\")\n                return True\n            except Exception as e:\n                print(f\"Upload failed: {e}\")\n                attempt += 1\n                if attempt < self.retries:\n                    print(f\"Retrying... ({attempt}/{self.retries})\")\n                else:\n                    print(\"Max retries reached. Upload failed.\")\n                    return False\n\n# Example usage:\n# For 1GB video file (1 hour timeout, 3 retries)\nvideo_uploader = S3Uploader(timeout=3600, retries=3)\nvideo_data = b\"1\" * (1024 * 1024 * 1024)  # 1GB of data\nvideo_uploader.upload(video_data)\n\n# For 1KB JSON file (500ms timeout, 1 retry)\njson_uploader = S3Uploader(timeout=0.5, retries=1)\njson_data = b\"1\" * 1024  # 1KB of data\njson_uploader.upload(json_data)\n```\n\nIn this redesign, the `S3Uploader` class takes `timeout` and `retries` as parameters, allowing the rules to be adjusted based on the type of file being uploaded. This separation of rules from work makes the class more flexible and easier to maintain."
      },
      "skill": {
        "pass": true,
        "response_preview": "I'll refactor the S3Uploader class to separate the policy (timeout and retry rules) from the mechani...",
        "response_full": "I'll refactor the S3Uploader class to separate the policy (timeout and retry rules) from the mechanism (upload functionality). This will allow us to use the same upload mechanism with different policies for different use cases.\n\n```python\nclass S3Uploader:\n    def __init__(self, client):\n        self.client = client\n        self.policies = {}  # Will store different policies for different use cases\n\n    def register_policy(self, policy_name, policy_config):\n        \"\"\"Register a new policy for different timeout/retry rules\"\"\"\n        self.policies[policy_name] = policy_config\n\n    def upload(self, data, bucket, key, policy_name=\"default\"):\n        \"\"\"Upload data to S3 with specified policy\"\"\"\n        if policy_name not in self.policies:\n            raise ValueError(f\"Policy {policy_name} not found\")\n        \n        policy = self.policies[policy_name]\n        \n        # Apply the policy to the upload operation\n        return self._upload_with_policy(data, bucket, key, policy)\n\n    def _upload_with_policy(self, data, bucket, key, policy):\n        \"\"\"Core upload mechanism that can work with any policy\"\"\"\n        max_retries = policy[\"max_retries\"]\n        timeout_seconds = policy[\"timeout_seconds\"]\n        \n        # Implement the upload logic here\n        # This is the reusable mechanism\n        for attempt in range(max_retries):\n            try:\n                # Simulate upload (replace with actual S3 upload)\n                print(f\"Uploading {len(data)} bytes to {bucket}/{key}\")\n                \n                # In a real implementation, this would be:\n                # self.client.put_object(Bucket=bucket, Key=key, Body=data)\n                \n                # Simulate success\n                print(\"Upload successful\")\n                return True\n                \n            except Exception as e:\n                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n                \n                if attempt == max_retries - 1:\n                    raise\n                    \n                # Wait before retry (in real implementation, use exponential backoff)\n                import time\n                time.sleep(1)\n                \n        return False\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Create a mock S3 client (replace with real boto3 client)\n    class MockS3Client:\n        def put_object(self, Bucket, Key, Body):\n            print(f\"Mock upload: {len(Body)} bytes to {Bucket}/{Key}\")\n            return {\"ResponseMetadata\": {\"HTTPStatusCode\": 200}}\n    \n    client = MockS3Client()\n    uploader = S3Uploader(client)\n    \n    # Register different policies for different use cases\n    uploader.register_policy(\"video\", {\"max_retries\": 5, \"timeout_seconds\": 3600})\n    uploader.register_policy(\"json\", {\"max_retries\": 3, \"timeout_seconds\": 0.5})\n    \n    # Create test data\n    video_data = b\"0\" * (1024 * 1024 * 1024)  # 1GB video\n    json_data = b'{\"test\": \"data\"}'  # 1KB JSON\n    \n    # Upload with different policies\n    print(\"Uploading video (1GB):\")\n    uploader.upload(video_data, \"my-bucket\", \"videos/large.mp4\", \"video\")\n    \n    print(\"\\nUploading JSON (1KB):\")\n    uploader.upload(json_data, \"my-bucket\", \"data/small.json\", \"json\")\n```\n\n**Key Principles Applied:**\n\n1. **Policy Separation**: The timeout and retry rules are separated from the upload mechanism\n2. **Reusability**: The core upload mechanism can work with any policy\n3. **Flexibility**: Different policies can be registered for different use cases\n4. **Testability**: Policies can be changed without modifying the upload mechanism\n\n**When to Use This Pattern:**\n\n- When the same mechanism needs to work with different rules\n- When policies change independently of the core functionality\n- When different use cases require different configuration\n- When rules need to be updated without code changes\n\n**Indicators You Need This Pattern:**\n\n- Different timeouts or retry strategies for different use cases\n- Rules that change independently of the core functionality\n- Multiple configurations for different scenarios\n- Need to update policies without code changes\n\nThis refactoring allows you to use the same upload mechanism with different policies for different use cases, making your code more flexible and maintainable."
      }
    },
    {
      "name": "cache_expiration_strategy",
      "input": "We have a simple `Cache` class. Currently, it deletes items if they are older than 1 hour.\n\nWe want to support different expiration rules for different data types (e.g., \"Expire if not accessed in 10 mins\" vs \"Expire at midnight specific timezone\").\n\nShow how you would restructure the Cache to separate the storage mechanism from the expiration logic.",
      "expected": {
        "focus": "Does the Cache delegate the \"should I expire?\" decision to a separate policy?"
      },
      "baseline": {
        "pass": true,
        "response_preview": "To restructure the `Cache` class to separate the storage mechanism from the expiration logic, we can...",
        "response_full": "To restructure the `Cache` class to separate the storage mechanism from the expiration logic, we can introduce a new `ExpirationPolicy` class that defines the expiration rules. The `Cache` class will then use this policy to determine when to expire items.\n\nHere's how you can implement this:\n\n```python\nfrom datetime import datetime, timedelta\nfrom abc import ABC, abstractmethod\n\nclass ExpirationPolicy(ABC):\n    @abstractmethod\n    def is_expired(self, last_accessed: datetime) -> bool:\n        pass\n\nclass TimeBasedExpirationPolicy(ExpirationPolicy):\n    def __init__(self, duration: timedelta):\n        self.duration = duration\n\n    def is_expired(self, last_accessed: datetime) -> bool:\n        return datetime.now() - last_accessed > self.duration\n\nclass Cache:\n    def __init__(self, expiration_policy: ExpirationPolicy):\n        self.storage = {}\n        self.expiration_policy = expiration_policy\n\n    def set(self, key, value):\n        self.storage[key] = (value, datetime.now())\n\n    def get(self, key):\n        if key not in self.storage:\n            return None\n        value, last_accessed = self.storage[key]\n        if self.expiration_policy.is_expired(last_accessed):\n            del self.storage[key]\n            return None\n        self.storage[key] = (value, datetime.now())\n        return value\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Create a cache that expires items after 10 minutes\n    expiration_policy = TimeBasedExpirationPolicy(timedelta(minutes=10))\n    cache = Cache(expiration_policy)\n\n    # Set and get values\n    cache.set(\"key1\", \"value1\")\n    print(cache.get(\"key1\"))  # Should print \"value1\"\n\n    # Wait for more than 10 minutes and try to get the value again\n    # print(cache.get(\"key1\"))  # Should print None\n```\n\nIn this implementation:\n- The `ExpirationPolicy` class is an abstract base class that defines the interface for expiration policies.\n- The `TimeBasedExpirationPolicy` class is a concrete implementation of the `ExpirationPolicy` that expires items based on a time duration.\n- The `Cache` class uses an `ExpirationPolicy` to determine when to expire items."
      },
      "skill": {
        "pass": true,
        "response_preview": "```python\nclass Cache:\n    def __init__(self):\n        self.storage = {}\n        self.expiration_pol...",
        "response_full": "```python\nclass Cache:\n    def __init__(self):\n        self.storage = {}\n        self.expiration_policies = {}\n\n    def set_expiration_policy(self, data_type, policy):\n        \"\"\"Set expiration policy for a specific data type\"\"\"\n        self.expiration_policies[data_type] = policy\n\n    def add(self, key, value, data_type):\n        \"\"\"Add item to cache with expiration policy\"\"\"\n        if data_type not in self.expiration_policies:\n            raise ValueError(f\"No expiration policy set for data type: {data_type}\")\n        \n        self.storage[key] = {\n            'value': value,\n            'data_type': data_type,\n            'created_at': datetime.now()\n        }\n\n    def get(self, key):\n        \"\"\"Get item from cache with expiration check\"\"\"\n        if key not in self.storage:\n            return None\n        \n        item = self.storage[key]\n        policy = self.expiration_policies[item['data_type']]\n        \n        if policy.is_expired(item['created_at']):\n            del self.storage[key]\n            return None\n        \n        return item['value']\n\n# Example expiration policies\nclass TimeBasedExpiration:\n    def __init__(self, max_age_minutes):\n        self.max_age = timedelta(minutes=max_age_minutes)\n    \n    def is_expired(self, created_at):\n        return datetime.now() - created_at > self.max_age\n\nclass MidnightExpiration:\n    def __init__(self, timezone_str):\n        self.timezone = pytz.timezone(timezone_str)\n    \n    def is_expired(self, created_at):\n        # Check if it's midnight in the specified timezone\n        now = datetime.now(self.timezone)\n        return now.hour == 0 and now.minute == 0\n\n# Usage\ncache = Cache()\n\n# Set different expiration policies\ncache.set_expiration_policy('user_data', TimeBasedExpiration(60))  # 1 hour\ncache.set_expiration_policy('logs', MidnightExpiration('US/Eastern'))\n\n# Add items with different expiration rules\ncache.add('user_123', {'name': 'John'}, 'user_data')\ncache.add('log_456', {'action': 'login'}, 'logs')\n```"
      }
    }
  ],
  "judgment": {
    "principle_better": "B",
    "quality_better": "B",
    "overall_better": "B",
    "option_a_rating": "regular",
    "option_b_rating": "good",
    "score": 100,
    "reasoning": "Solution B demonstrates better adherence to the principle of separating business rules from execution mechanisms. Solution A attempts separation but has implementation issues, while Solution B correctly implements the separation pattern with proper interfaces and clear separation of concerns. Solution B is more maintainable, testable, and flexible, making it the better overall solution."
  },
  "timestamp": "2026-02-07T22:55:27",
  "provider": "ollama"
}