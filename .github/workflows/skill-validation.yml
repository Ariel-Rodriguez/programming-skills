name: Skill Validation

on:
  issue_comment:
    types: [created]

permissions:
  pull-requests: write
  contents: read

jobs:
  prepare:
    runs-on: ubuntu-latest
    if: github.event.issue.pull_request && contains(github.event.comment.body, '/test')
    outputs:
      matrix: ${{ steps.matrix.outputs.result }}
    
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5

      - name: Generate matrix
        id: matrix
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
          COMMENT: ${{ github.event.comment.body }}
        run: |
          echo "Generating matrix for PR $PR_NUMBER"
          python3 ci/orchestrate_evaluations.py "$PR_NUMBER" --matrix-only --filter-provider all > /tmp/matrix.json 2>&1
          
          echo "Matrix content:"
          cat /tmp/matrix.json
          
          echo "Setting output..."
          echo "result<<EOF" >> $GITHUB_OUTPUT
          cat /tmp/matrix.json >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          echo "Matrix size:"
          python3 -c "import json; m=json.load(open('/tmp/matrix.json')); print(f\"{len(m['include'])} jobs\")"

  evaluate:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix: ${{ fromJson(needs.prepare.outputs.matrix) }}
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        if: matrix.provider == 'copilot'
        with:
          node-version: '20'
          
      - name: Install Copilot CLI
        if: matrix.provider == 'copilot'
        run: npm install -g @github/copilot
        
      - uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Evaluate ${{ matrix.display_name }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COPILOT_GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OLLAMA_API_KEY: ${{ secrets.OLLAMA_API_KEY }}
        run: |
          CMD="uv run --project tests --frozen tests/evaluator.py"
          CMD="$CMD --provider ${{ matrix.provider }}"
          CMD="$CMD --model ${{ matrix.model }}"
          CMD="$CMD --judge --verbose --report --threshold 50"
          
          if [ -n "${{ matrix.extra_args }}" ]; then
            CMD="$CMD ${{ matrix.extra_args }}"
          fi
          
          if [ -n "${{ matrix.skill }}" ]; then
            CMD="$CMD --skill ${{ matrix.skill }}"
          else
            CMD="$CMD --all"
          fi
          
          echo "Running: $CMD"
          eval "$CMD"

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ format('results-{0}-{1}-{2}', matrix.provider, replace(matrix.model, ':', '-'), matrix.skill || 'all') }}
          path: tests/results/
          retention-days: 1

  consolidate:
    needs: evaluate
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/download-artifact@v4
        with:
          path: tests/results/

      - name: Consolidate results
        run: python3 ci/consolidate_results.py || echo "# Results pending" > comment.md

      - name: Post to PR
        uses: marocchino/sticky-pull-request-comment@v2
        if: hashFiles('comment.md') != ''
        with:
          number: ${{ github.event.issue.number }}
          path: comment.md
